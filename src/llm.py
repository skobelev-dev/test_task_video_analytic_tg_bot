import os

from langchain_ollama import ChatOllama
from src.logger import logger
print("here")
from src.db.utils import get_db_schema

base_url = os.getenv("OLLAMA_BASE_URL", "http://ollama:11434")
llm = OllamaLLM(
    model="llama3.1",  # –°–∫–∞—á–∞–π—Ç–µ –∑–∞—Ä–∞–Ω–µ–µ: docker exec ollama ollama pull llama3.1
    base_url=base_url
)


def taking_the_ask(ask: str) -> str:
    logger.debug(msg=f"{ask=}")
    logger.info("The ask is ready to be asked")
    llm_response = llm.invoke(ask)
    content = llm_response.content
    logger.info("llm response is taken")
    logger.debug(f"{content=}")
    print(content)
    return content


SYSTEM_PROMPT = """
üîß –¢—ã SQL-—ç–∫—Å–ø–µ—Ä—Ç –¥–ª—è PostgreSQL. –ü—Ä–µ–æ–±—Ä–∞–∑—É–π –∑–∞–ø—Ä–æ—Å—ã –ù–ê –†–£–°–°–ö–û–ú –≤ SQL.

üìä –°–•–ï–ú–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•:
{table_schema}

‚ö†Ô∏è –ü–†–ê–í–ò–õ–ê (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û):
1. –ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û —Ç–∞–±–ª–∏—Ü—ã/–ø–æ–ª—è –∏–∑ —Å—Ö–µ–º—ã –≤—ã—à–µ
2. –í–°–ï–ì–î–ê –¥–æ–±–∞–≤–ª—è–π LIMIT 100
3. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π DELETE/UPDATE/DROP/INSERT
4. –î–ª—è –¥–∞—Ç: '2025-01-01' –∏–ª–∏ NOW() - INTERVAL '1 day'
5. –†—É—Å—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –≤ –ë–î –∫–∞–∫ –µ—Å—Ç—å (–Ω–µ –ø–µ—Ä–µ–≤–æ–¥–∏)
6. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å - –≤–µ—Ä–Ω–∏ "–ù–µ –º–æ–≥—É —Å–æ—Å—Ç–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å"

üìã –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (–°–¢–†–û–ì–û):
SQL: SELECT ... LIMIT 100;

text

–ü—Ä–∏–º–µ—Ä:
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: "–ø–æ–∫–∞–∂–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
–û—Ç–≤–µ—Ç:
SQL: SELECT * FROM users LIMIT 100;

text
"""

def build_prompt(question: str) -> str:
    schema = get_db_schema()
    return SYSTEM_PROMPT.format(table_schema=schema) + f"\n\n‚ùì –ó–∞–ø—Ä–æ—Å: {question}"

if __name__ == '__main__':
    main()